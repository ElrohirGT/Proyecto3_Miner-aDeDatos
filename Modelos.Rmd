---
title: "Modelos"
author: "Flavio Galán, Gustavo Cruz, Pedro Guzmán"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true # table of content true
    toc_float: true  # upto three depths of headings (specified by #, ## and ###)
    theme: paper  # many options for theme, this one is my favorite.
    highlight: tango  # specifies the syntax highlighting style
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r Cargar librerias}
library(rio)
library(janitor)
library(ggplot2)
library(dplyr)
library(tidyr)
library(viridis)
library(scales)
library(readxl)
library(purrr)
library(plotly)
library(fastDummies)
library(hopkins)
library(fpc)
library(factoextra)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(NbClust) #Para determinar el número de clusters óptimo
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap)
library(flexclust)
library(ggrepel)
# Dependencias necesarias para el random Forest
# Ahora se usa ranger para randomForest y parallel para paralelizar y que sea mas rapido entrenar
library(randomForest) # al principio se uso randomForest pero era muy lento
library(ranger)
library(parallel)
library(caret)
library(forcats)
library(data.table)
library(tidyverse)
```

```{r Carga de los datos}
data_2013 <- import("Datos/2013.sav")
data_2014 <- import("Datos/2014.sav")
data_2015 <- import("Datos/2015.sav")
data_2016 <- import("Datos/2016.sav")
data_2017 <- import("Datos/2017.sav")
data_2018 <- import("Datos/2018.sav")
data_2019 <- import("Datos/2019.sav")
data_2020 <- import("Datos/2020.sav")
data_2021 <- import("Datos/2021.sav")
data_2022 <- import("Datos/2022.sav")
data_2023 <- import("Datos/2023.sav")

compare_df_cols(data_2013, data_2014, data_2015,data_2016,data_2017,data_2018,data_2019,data_2020,data_2021,data_2022,data_2023)
```


```{r Unión de los datos}

original <- import("Datos/2023.sav")

addToDataset <- function(year) {
  data <- import(paste("Datos/", year, ".sav", sep=""))
  # reduced <- data[,colnames(original)]
  original <<- bind_rows(original, data)
}

ifValueConvertToNA <- function(column, values) {
  # print(paste("Removing ignored values from:", column))
  original[,c(column)] <<- ifelse(original[,c(column)] %in% values, NA, original[,c(column)])
}

for (year in 2013:2022) {
  addToDataset(year)
}

ignoredValues <- c(9, 99, 999, 9999)
affectedColumns <- c(
  "VIC_EDAD",
  "TOTAL_HIJOS",
  "NUM_HIJ_HOM",
  "NUM_HIJ_MUJ",
  "VIC_ALFAB",
  "VIC_ESCOLARIDAD",
  "VIC_EST_CIV",
  "VIC_GRUPET",
  "VIC_NACIONAL",
  "VIC_TRABAJA",
  "VIC_OCUP",
  "VIC_DEDICA",
  "VIC_DISC",
  "TIPO_DISCAQ",
  "OTRAS_VICTIMAS",
  "VIC_OTRAS_HOM",
  "VIC_OTRAS_MUJ",
  "VIC_OTRAS_N_OS",
  "VIC_OTRAS_N_AS",
  "HEC_DIA",
  "HEC_MES",
  "HEC_ANO",
  "HEC_DEPTO",
  "HEC_DEPTOMCPIO",
  "HEC_AREA",
  "HEC_RECUR_DENUN",
  "INST_DONDE_DENUNCIO",
  "AGR_EDAD",
  "AGR_ALFAB",
  "AGR_ESCOLARIDAD",
  "AGR_EST_CIV",
  "AGR_GURPET",
  "AGR_NACIONAL",
  "AGR_TRABAJA",
  "AGR_OCUP",
  "AGR_DEDICA",
  "AGRESORES_OTROS_TOTAL",
  "AGR_OTROS_HOM",
  "AGR_OTRAS_MUJ",
  "AGR_OTROS_N_OS",
  "AGR_OTRAS_N_AS",
  "CONDUCENTE",
  "LEY_APLICABLE",
  "ARTICULOVIF1",
  "ARTICULOVIF2",
  "ARTICULOVIF3",
  "ARTICULOVIF4",
  "ARTICULOVCM1",
  "ARTICULOVCM2",
  "ARTICULOVCM3",
  "ARTICULOVCM4",
  "ARTICULOCODPEN1",
  "ARTICULOCODPEN2",
  "ARTICULOCODPEN3",
  "ARTICULOCODPEN4",
  "ARTICULOTRAS1",
  "ARTICULOTRAS2",
  "ARTICULOTRAS3",
  "ARTICULOTRAS4",
  "MEDIDAS_SEGURIDAD",
  "ORGANISMO_REMITE",
  "QUIEN_REPORTA",
  "ORGANISMO_JURISDICCIONAL"
)


for (col in affectedColumns) {
	ifValueConvertToNA(col, ignoredValues)
}

# Ignorar también TIPO_MEDIDA, se ignora con valor z
ifValueConvertToNA("TIPO_MEDIDA", c("z"))

# Por alguna razón se crea esta columna, todos sus valores son NAN así que la borramos.
original$`filter_$` <- NULL
```


```{r Preparacion de datos RF}
data_model <- as.data.table(original)

data_model[, ratio_age := AGR_EDAD / VIC_EDAD]

data_model <- data_model[!is.na(ratio_age) & is.finite(ratio_age) & ratio_age > 0]

all_cols <- c("ratio_age", names(data_model)[names(data_model) != "ratio_age"])
available_cols <- intersect(all_cols, names(data_model))

data_model <- data_model[!is.na(ratio_age), ..available_cols]

non_num_cols <- names(data_model)[!sapply(data_model, is.numeric)]
for (col in non_num_cols) {
  set(data_model, j = col, value = as.factor(data_model[[col]]))
}

set.seed(2077)
n_train <- round(0.8 * nrow(data_model))
train_idx <- sample(nrow(data_model), n_train)
train <- data_model[train_idx]
test <- data_model[-train_idx]
```

```{r Modelos rf}
ncores <- min(detectCores() - 1, 16)  # Limitamos a un máximo práctico

# 2) Imputación más robusta - asegurando CERO NAs
robust_impute <- function(df) {
  df_copy <- copy(df)
  
  # Para cada columna
  for (col in names(df_copy)) {
    # Si es numérica, imputamos con la mediana
    if (is.numeric(df_copy[[col]])) {
      # Verificamos si hay NAs
      na_idx <- which(is.na(df_copy[[col]]))
      if (length(na_idx) > 0) {
        # Si todos son NA, usamos 0
        if (all(is.na(df_copy[[col]]))) {
          set(df_copy, na_idx, col, 0)
        } else {
          # Usamos la mediana para imputar
          med_val <- median(df_copy[[col]], na.rm = TRUE)
          set(df_copy, na_idx, col, med_val)
        }
      }
    } 
    # Si es factor, imputamos con el nivel más frecuente
    else if (is.factor(df_copy[[col]])) {
      # Verificamos si hay NAs
      na_idx <- which(is.na(df_copy[[col]]))
      if (length(na_idx) > 0) {
        # Si todos son NA, creamos un nivel "Desconocido"
        if (all(is.na(df_copy[[col]]))) {
          # Añadimos nivel "Desconocido" si no existe
          if (!("Desconocido" %in% levels(df_copy[[col]]))) {
            levels(df_copy[[col]]) <- c(levels(df_copy[[col]]), "Desconocido")
          }
          set(df_copy, na_idx, col, "Desconocido")
        } else {
          # Usamos el nivel más frecuente
          freq_table <- table(df_copy[[col]], useNA = "no")
          if (length(freq_table) > 0) {
            most_freq <- names(which.max(freq_table))
            set(df_copy, na_idx, col, most_freq)
          } else {
            # Si no hay niveles no-NA, creamos "Desconocido"
            if (!("Desconocido" %in% levels(df_copy[[col]]))) {
              levels(df_copy[[col]]) <- c(levels(df_copy[[col]]), "Desconocido")
            }
            set(df_copy, na_idx, col, "Desconocido")
          }
        }
      }
    }
    # Para cualquier otro tipo (character, etc.)
    else if (is.character(df_copy[[col]])) {
      # Convertimos a factor primero
      df_copy[[col]] <- as.factor(df_copy[[col]])
      # Identificamos NAs
      na_idx <- which(is.na(df_copy[[col]]))
      if (length(na_idx) > 0) {
        # Imputamos con "Desconocido"
        set(df_copy, na_idx, col, "Desconocido")
      }
    }
    # Para cualquier otro tipo de datos
    else {
      # Convertimos a character y luego a factor
      na_idx <- which(is.na(df_copy[[col]]))
      if (length(na_idx) > 0) {
        df_copy[[col]] <- as.character(df_copy[[col]])
        set(df_copy, na_idx, col, "Desconocido")
        df_copy[[col]] <- as.factor(df_copy[[col]])
      }
    }
  }
  
  # Verificación final
  if (any(is.na(df_copy))) {
    # Identificar columnas que aún tienen NAs
    na_cols <- colnames(df_copy)[colSums(is.na(df_copy)) > 0]
    # Eliminar esas columnas
    message("ADVERTENCIA: Eliminando columnas con NAs persistentes: ", paste(na_cols, collapse=", "))
    df_copy <- df_copy[, .SD, .SDcols = setdiff(names(df_copy), na_cols)]
  }
  
  return(df_copy)
}

# Aplicamos la imputación robusta
train_imp <- robust_impute(copy(train))
test_imp <- robust_impute(copy(test))

# Garantizamos que test tenga los mismos niveles de factores que train
for (col in names(train_imp)) {
  if (is.factor(train_imp[[col]]) && col %in% names(test_imp)) {
    # Obtener todos los niveles de ambos conjuntos
    train_levels <- levels(train_imp[[col]])
    test_levels <- levels(test_imp[[col]])
    
    # Unificar niveles
    all_levels <- unique(c(train_levels, test_levels))
    
    # Establecer los mismos niveles para ambos
    train_imp[[col]] <- factor(train_imp[[col]], levels = all_levels)
    test_imp[[col]] <- factor(test_imp[[col]], levels = all_levels)
  }
}

# 3) Optimización de factores - más eficiente y robusta
for (col in names(train_imp)) {
  if (is.factor(train_imp[[col]]) && length(levels(train_imp[[col]])) > 20) {
    # Obtenemos los niveles más frecuentes
    top_levels <- names(sort(table(train_imp[[col]]), decreasing = TRUE)[1:20])
    
    # Verificamos que top_levels no sea NULL o vacío
    if (length(top_levels) == 0) {
      # Si no hay niveles válidos, cambiamos a caracteres simples
      train_imp[[col]] <- as.character(train_imp[[col]])
      test_imp[[col]] <- as.character(test_imp[[col]])
      next
    }
    
    # Agrupamos el resto como "Other"
    train_levels_to_change <- setdiff(levels(train_imp[[col]]), c(top_levels, "Other"))
    if (length(train_levels_to_change) > 0) {
      levels(train_imp[[col]])[match(train_levels_to_change, levels(train_imp[[col]]))] <- "Other"
    }
    
    test_levels_to_change <- setdiff(levels(test_imp[[col]]), c(top_levels, "Other"))
    if (length(test_levels_to_change) > 0) {
      levels(test_imp[[col]])[match(test_levels_to_change, levels(test_imp[[col]]))] <- "Other"
    }
    
    # Aseguramos que los factores tengan los mismos niveles
    combined_levels <- unique(c(levels(train_imp[[col]]), levels(test_imp[[col]])))
    train_imp[[col]] <- factor(train_imp[[col]], levels = combined_levels)
    test_imp[[col]] <- factor(test_imp[[col]], levels = combined_levels)
  }
}

# 4) Verificación final de NAs - SUPER robusta
if (any(is.na(train_imp)) || any(is.na(test_imp))) {
  # Último recurso: eliminar columnas problemáticas
  na_cols_train <- names(train_imp)[colSums(is.na(train_imp)) > 0]
  na_cols_test <- names(test_imp)[colSums(is.na(test_imp)) > 0]
  problem_cols <- unique(c(na_cols_train, na_cols_test))
  
  if (length(problem_cols) > 0) {
    message("ADVERTENCIA: Eliminando columnas problemáticas como último recurso: ", 
           paste(problem_cols, collapse=", "))
    
    # Verificamos que ratio_age no esté en las columnas problemáticas
    if ("ratio_age" %in% problem_cols) {
      stop("La variable objetivo 'ratio_age' contiene NAs que no se pueden eliminar. Revisa tus datos.")
    }
    
    # Eliminamos las columnas problemáticas
    cols_to_keep <- setdiff(names(train_imp), problem_cols)
    train_imp <- train_imp[, ..cols_to_keep]
    test_imp <- test_imp[, ..cols_to_keep]
  }
}

# Verificación FINAL de NAs - máxima seguridad
stopifnot("Aún hay NAs en train_imp" = sum(is.na(train_imp)) == 0)
stopifnot("Aún hay NAs en test_imp" = sum(is.na(test_imp)) == 0)

# 5) Definición de modelos más eficiente
p <- ncol(train_imp) - 1  # Número de predictores

# Modelo 1: Menos árboles, menos variables por split (enfoque conservador)
train_model1 <- function() {
  set.seed(123)
  ranger(
    ratio_age ~ ., 
    data = train_imp,
    num.trees = 200,                 # Menos árboles para velocidad
    mtry = floor(sqrt(p)),           # Enfoque tradicional: sqrt(p)
    min.node.size = 15,              # Nodos más grandes (menos sobreajuste)
    max.depth = 15,                  # Profundidad limitada
    sample.fraction = 0.7,           # Submuestreo
    num.threads = ncores,
    verbose = FALSE,                 
    importance = "impurity"          # Más rápido
  )
}

# Modelo 2: Número medio de árboles, más variables por split
train_model2 <- function() {
  set.seed(456)
  ranger(
    ratio_age ~ ., 
    data = train_imp,
    num.trees = 300,                 # Más árboles, mejor generalización
    mtry = floor(p/3),               # Más variables por split
    min.node.size = 5,               # Nodos más pequeños
    max.depth = 25,                  # Mayor profundidad
    sample.fraction = 0.8,           # Más muestras
    num.threads = ncores,
    verbose = FALSE,
    importance = "impurity"
  )
}

# Modelo 3: Más árboles, balance de variables
train_model3 <- function() {
  set.seed(789)
  ranger(
    ratio_age ~ ., 
    data = train_imp,
    num.trees = 500,                 # Muchos árboles
    mtry = floor(p * 0.4),           # Balance de variables
    min.node.size = 10,              # Balance en tamaño de nodos
    max.depth = 20,                  # Balance en profundidad
    sample.fraction = 0.75,          # Balance en submuestreo
    num.threads = ncores,
    verbose = FALSE,
    importance = "impurity"
  )
}

# Entrenamos los tres modelos explícitamente según requerimiento
message("Entrenando modelo 1 (Conservador)")
rf1 <- train_model1()
message("Entrenando modelo 2 (Intermedio)")
rf2 <- train_model2()
message("Entrenando modelo 3 (Agresivo)")
rf3 <- train_model3()

# Evaluamos los modelos
pred1 <- predict(rf1, data = test_imp)$predictions
pred2 <- predict(rf2, data = test_imp)$predictions
pred3 <- predict(rf3, data = test_imp)$predictions

# Calculamos métricas
calc_metrics <- function(pred, actual) {
  c(
    MAE = mean(abs(pred - actual)),
    RMSE = sqrt(mean((pred - actual)^2)),
    R2 = 1 - sum((actual - pred)^2) / sum((actual - mean(actual))^2)
  )
}

metrics1 <- calc_metrics(pred1, test_imp$ratio_age)
metrics2 <- calc_metrics(pred2, test_imp$ratio_age)
metrics3 <- calc_metrics(pred3, test_imp$ratio_age)

# Comparamos los modelos
all_metrics <- rbind(
  Model1 = metrics1,
  Model2 = metrics2,
  Model3 = metrics3
)

# Determinamos el mejor modelo basado en RMSE
best_idx <- which.min(all_metrics[, "RMSE"])
best_model_name <- paste("Modelo", best_idx)

message("El mejor modelo es ", best_model_name, " con RMSE = ", all_metrics[best_idx, "RMSE"])

# Obtenemos importancia de variables del mejor modelo
var_importance <- switch(best_idx,
  "1" = importance(rf1),
  "2" = importance(rf2),
  "3" = importance(rf3)
)

# Ordenamos por importancia
var_importance <- sort(var_importance, decreasing = TRUE)

message("Entrenando modelo FINAL con parámetros optimizados")
# Obtenemos los parámetros del mejor modelo
best_params <- switch(best_idx,
  "1" = list(trees = 200, mtry = floor(sqrt(p)), node_size = 15, depth = 15, fraction = 0.7),
  "2" = list(trees = 500, mtry = floor(p/3), node_size = 5, depth = 25, fraction = 0.8),
  "3" = list(trees = 800, mtry = floor(p * 0.4), node_size = 10, depth = 20, fraction = 0.75)
)

# Creamos un modelo final con los parámetros optimizados
set.seed(2077)
rf_final <- ranger(
  ratio_age ~ ., 
  data = train_imp,
  num.trees = best_params$trees + 100,    # Aumentamos ligeramente los árboles
  mtry = best_params$mtry,                # Mantenemos la mejor configuración de variables
  min.node.size = best_params$node_size,  # Mantenemos el mejor tamaño de nodo
  max.depth = best_params$depth,          # Mantenemos la mejor profundidad
  sample.fraction = best_params$fraction, # Mantenemos la mejor fracción de muestreo
  num.threads = ncores,
  verbose = FALSE,
  importance = "impurity"
)

# Evaluamos el modelo final
pred_final <- predict(rf_final, data = test_imp)$predictions
final_metrics <- c(
  MAE = mean(abs(pred_final - test_imp$ratio_age)),
  RMSE = sqrt(mean((pred_final - test_imp$ratio_age)^2)),
  R2 = 1 - sum((test_imp$ratio_age - pred_final)^2) / 
       sum((test_imp$ratio_age - mean(test_imp$ratio_age))^2)
)

# Mostramos los resultados finales
message("Resultados del modelo FINAL:")
print(final_metrics)

# 10) Guardar el mejor modelo para uso futuro
saveRDS(rf_final, "rf_model_final.rds")

# 11) Gráfico de predicción vs real
if (require(ggplot2)) {
  prediction_df <- data.frame(
    Real = test_imp$ratio_age,
    Predicho = pred_final
  )
  
  plot_pred <- ggplot(prediction_df, aes(x = Real, y = Predicho)) +
    geom_point(alpha = 0.5) +
    geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
    labs(title = "Predicción vs Valor Real",
         x = "Ratio de Edad Real",
         y = "Ratio de Edad Predicho") +
    theme_minimal()
  
  print(plot_pred)
}

# 12) Análisis del modelo final
message("Resumen de importancia de variables (top 5):")
print(head(var_importance, 5))
message("Análisis completado. El modelo final ha sido guardado como 'rf_model_final.rds'")
```
